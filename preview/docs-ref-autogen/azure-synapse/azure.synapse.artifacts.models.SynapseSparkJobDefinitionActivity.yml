### YamlMime:PythonClass
uid: azure.synapse.artifacts.models.SynapseSparkJobDefinitionActivity
name: SynapseSparkJobDefinitionActivity
fullName: azure.synapse.artifacts.models.SynapseSparkJobDefinitionActivity
module: azure.synapse.artifacts.models
inheritances:
- azure.synapse.artifacts.models._models_py3.ExecutionActivity
summary: 'Execute spark job activity.


  All required parameters must be populated in order to send to Azure.'
constructor:
  syntax: 'SynapseSparkJobDefinitionActivity(*, name: str, spark_job: _models.SynapseSparkJobReference,
    additional_properties: Dict[str, MutableMapping[str, Any]] | None = None, description:
    str | None = None, depends_on: List[_models.ActivityDependency] | None = None,
    user_properties: List[_models.UserProperty] | None = None, linked_service_name:
    _models.LinkedServiceReference | None = None, policy: _models.ActivityPolicy |
    None = None, arguments: List[Any] | None = None, file: MutableMapping[str, Any]
    | None = None, class_name: MutableMapping[str, Any] | None = None, files: List[Any]
    | None = None, target_big_data_pool: _models.BigDataPoolParametrizationReference
    | None = None, executor_size: MutableMapping[str, Any] | None = None, conf: MutableMapping[str,
    Any] | None = None, driver_size: MutableMapping[str, Any] | None = None, num_executors:
    int | None = None, **kwargs)'
  parameters:
  - name: additional_properties
    description: 'Unmatched properties from the message are deserialized to this

      collection.'
    types:
    - <xref:dict>[<xref:str>, <xref:JSON>]
  - name: name
    description: Activity name. Required.
    types:
    - <xref:str>
  - name: description
    description: Activity description.
    types:
    - <xref:str>
  - name: depends_on
    description: Activity depends on condition.
    types:
    - <xref:azure.synapse.aio.operations_async.SparkBatchOperations.list>[<xref:azure.synapse.artifacts.models.ActivityDependency>]
  - name: user_properties
    description: Activity user properties.
    types:
    - <xref:azure.synapse.aio.operations_async.SparkBatchOperations.list>[<xref:azure.synapse.artifacts.models.UserProperty>]
  - name: linked_service_name
    description: Linked service reference.
    types:
    - <xref:azure.synapse.artifacts.models.LinkedServiceReference>
  - name: policy
    description: Activity policy.
    types:
    - <xref:azure.synapse.artifacts.models.ActivityPolicy>
  - name: spark_job
    description: Synapse spark job reference. Required.
    types:
    - <xref:azure.synapse.artifacts.models.SynapseSparkJobReference>
  - name: arguments
    description: User specified arguments to SynapseSparkJobDefinitionActivity.
    types:
    - <xref:azure.synapse.aio.operations_async.SparkBatchOperations.list>[<xref:any>]
  - name: file
    description: 'The main file used for the job, which will override the ''file''
      of the spark job

      definition you provide. Type: string (or Expression with resultType string).'
    types:
    - <xref:JSON>
  - name: class_name
    description: 'The fully-qualified identifier or the main class that is in the
      main

      definition file, which will override the ''className'' of the spark job definition
      you provide.

      Type: string (or Expression with resultType string).'
    types:
    - <xref:JSON>
  - name: files
    description: 'Additional files used for reference in the main definition file,
      which will

      override the ''files'' of the spark job definition you provide.'
    types:
    - <xref:azure.synapse.aio.operations_async.SparkBatchOperations.list>[<xref:any>]
  - name: target_big_data_pool
    description: 'The name of the big data pool which will be used to execute the

      spark batch job, which will override the ''targetBigDataPool'' of the spark
      job definition you

      provide.'
    types:
    - <xref:azure.synapse.artifacts.models.BigDataPoolParametrizationReference>
  - name: executor_size
    description: 'Number of core and memory to be used for executors allocated in
      the

      specified Spark pool for the job, which will be used for overriding ''executorCores''
      and

      ''executorMemory'' of the spark job definition you provide. Type: string (or
      Expression with

      resultType string).'
    types:
    - <xref:JSON>
  - name: conf
    description: 'Spark configuration properties, which will override the ''conf''
      of the spark job

      definition you provide.'
    types:
    - <xref:JSON>
  - name: driver_size
    description: 'Number of core and memory to be used for driver allocated in the

      specified Spark pool for the job, which will be used for overriding ''driverCores''
      and

      ''driverMemory'' of the spark job definition you provide. Type: string (or Expression
      with

      resultType string).'
    types:
    - <xref:JSON>
  - name: num_executors
    description: 'Number of executors to launch for this job, which will override
      the

      ''numExecutors'' of the spark job definition you provide.'
    types:
    - <xref:int>
variables:
- description: 'Unmatched properties from the message are deserialized to this

    collection.'
  name: additional_properties
  types:
  - <xref:dict>[<xref:str>, <xref:JSON>]
- description: Activity name. Required.
  name: name
  types:
  - <xref:str>
- description: Type of activity. Required.
  name: type
  types:
  - <xref:str>
- description: Activity description.
  name: description
  types:
  - <xref:str>
- description: Activity depends on condition.
  name: depends_on
  types:
  - <xref:list>[<xref:azure.synapse.artifacts.models.ActivityDependency>]
- description: Activity user properties.
  name: user_properties
  types:
  - <xref:list>[<xref:azure.synapse.artifacts.models.UserProperty>]
- description: Linked service reference.
  name: linked_service_name
  types:
  - <xref:azure.synapse.artifacts.models.LinkedServiceReference>
- description: Activity policy.
  name: policy
  types:
  - <xref:azure.synapse.artifacts.models.ActivityPolicy>
- description: Synapse spark job reference. Required.
  name: spark_job
  types:
  - <xref:azure.synapse.artifacts.models.SynapseSparkJobReference>
- description: User specified arguments to SynapseSparkJobDefinitionActivity.
  name: arguments
  types:
  - <xref:list>[<xref:any>]
- description: 'The main file used for the job, which will override the ''file'' of
    the spark job

    definition you provide. Type: string (or Expression with resultType string).'
  name: file
  types:
  - <xref:JSON>
- description: 'The fully-qualified identifier or the main class that is in the main

    definition file, which will override the ''className'' of the spark job definition
    you provide.

    Type: string (or Expression with resultType string).'
  name: class_name
  types:
  - <xref:JSON>
- description: 'Additional files used for reference in the main definition file, which
    will

    override the ''files'' of the spark job definition you provide.'
  name: files
  types:
  - <xref:list>[<xref:any>]
- description: 'The name of the big data pool which will be used to execute the

    spark batch job, which will override the ''targetBigDataPool'' of the spark job
    definition you

    provide.'
  name: target_big_data_pool
  types:
  - <xref:azure.synapse.artifacts.models.BigDataPoolParametrizationReference>
- description: 'Number of core and memory to be used for executors allocated in the

    specified Spark pool for the job, which will be used for overriding ''executorCores''
    and

    ''executorMemory'' of the spark job definition you provide. Type: string (or Expression
    with

    resultType string).'
  name: executor_size
  types:
  - <xref:JSON>
- description: 'Spark configuration properties, which will override the ''conf'' of
    the spark job

    definition you provide.'
  name: conf
  types:
  - <xref:JSON>
- description: 'Number of core and memory to be used for driver allocated in the specified

    Spark pool for the job, which will be used for overriding ''driverCores'' and
    ''driverMemory'' of

    the spark job definition you provide. Type: string (or Expression with resultType
    string).'
  name: driver_size
  types:
  - <xref:JSON>
- description: 'Number of executors to launch for this job, which will override the

    ''numExecutors'' of the spark job definition you provide.'
  name: num_executors
  types:
  - <xref:int>
