### YamlMime:PythonClass
uid: azure.ai.evaluation.GleuScoreEvaluator
name: GleuScoreEvaluator
fullName: azure.ai.evaluation.GleuScoreEvaluator
module: azure.ai.evaluation
summary: "Evaluator that computes the BLEU Score between two strings.\n\nThe GLEU\
  \ (Google-BLEU) score evaluator measures the similarity between generated and reference\
  \ texts by\nevaluating n-gram overlap, considering both precision and recall. This\
  \ balanced evaluation, designed for\nsentence-level assessment, makes it ideal for\
  \ detailed analysis of translation quality. GLEU is well-suited for\nuse cases such\
  \ as machine translation, text summarization, and text generation.\n\n**Usage**\n\
  \n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\"\
  : [], \"backrefs\": [], \"xml:space\": \"preserve\", \"force\": false, \"language\"\
  : \"python\", \"highlight_args\": {}, \"linenos\": false} -->\n\n````python\n\n\
  \   eval_fn = GleuScoreEvaluator()\n   result = eval_fn(\n       response=\"Tokyo\
  \ is the capital of Japan.\",\n       ground_truth=\"The capital of Japan is Tokyo.\"\
  )\n   ````\n\n**Output format**\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {}, \"linenos\"\
  : false} -->\n\n````python\n\n   {\n       \"gleu_score\": 0.41\n   }\n   ````"
constructor:
  syntax: GleuScoreEvaluator()
