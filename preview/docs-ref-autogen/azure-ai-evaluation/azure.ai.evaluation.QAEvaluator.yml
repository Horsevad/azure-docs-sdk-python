### YamlMime:PythonClass
uid: azure.ai.evaluation.QAEvaluator
name: QAEvaluator
fullName: azure.ai.evaluation.QAEvaluator
module: azure.ai.evaluation
summary: "Initialize a question-answer evaluator configured for a specific Azure OpenAI\
  \ model.\n\n**Usage**\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\"\
  : [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\", \"force\"\
  : false, \"language\": \"python\", \"highlight_args\": {}, \"linenos\": false} -->\n\
  \n````python\n\n   eval_fn = QAEvaluator(model_config)\n   result = qa_eval(\n \
  \      query=\"Tokyo is the capital of which country?\",\n       response=\"Japan\"\
  ,\n       context=\"Tokyo is the capital of Japan.\",\n       ground_truth=\"Japan\"\
  \n   )\n   ````\n\n**Output format**\n\n<!-- literal_block {\"ids\": [], \"classes\"\
  : [], \"names\": [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {}, \"linenos\"\
  : false} -->\n\n````python\n\n   {\n       \"groundedness\": 3.5,\n       \"relevance\"\
  : 4.0,\n       \"coherence\": 1.5,\n       \"fluency\": 4.0,\n       \"similarity\"\
  : 3.0,\n       \"gpt_groundedness\": 3.5,\n       \"gpt_relevance\": 4.0,\n    \
  \   \"gpt_coherence\": 1.5,\n       \"gpt_fluency\": 4.0,\n       \"gpt_similarity\"\
  : 3.0,\n       \"f1_score\": 0.42\n   }\n   ````"
constructor:
  syntax: 'QAEvaluator(model_config, parallel: bool = True)'
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
  - name: parallel
    defaultValue: 'True'
