### YamlMime:PythonClass
uid: azure.ai.evaluation.GroundednessProEvaluator
name: GroundednessProEvaluator
fullName: azure.ai.evaluation.GroundednessProEvaluator
module: azure.ai.evaluation
summary: "> [!NOTE]\n> This is an experimental class, and may change at any time.\
  \ Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)\
  \ for more information.\n>\n\nInitialize a Groundedness Pro evaluator for determine\
  \ if the response is grounded\nin the query and context.\n\nIf this evaluator is\
  \ supplied to the *evaluate* function, the aggregated metric\nfor the groundedness\
  \ pro label will be \"groundedness_pro_passing_rate\".\n\n**Usage**\n\n<!-- literal_block\
  \ {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\":\
  \ [], \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
  highlight_args\": {}, \"linenos\": false} -->\n\n````python\n\n   azure_ai_project\
  \ = {\n       \"subscription_id\": \"<subscription_id>\",\n       \"resource_group_name\"\
  : \"<resource_group_name>\",\n       \"project_name\": \"<project_name>\",\n   }\n\
  \   credential = DefaultAzureCredential()\n\n   eval_fn = GroundednessProEvaluator(azure_ai_project,\
  \ credential)\n   result = eval_fn(query=\"What's the capital of France\", response=\"\
  Paris\", context=\"Paris.\")\n   ````\n\n**Output format**\n\n<!-- literal_block\
  \ {\"ids\": [], \"classes\": [], \"names\": [], \"dupnames\": [], \"backrefs\":\
  \ [], \"xml:space\": \"preserve\", \"force\": false, \"language\": \"python\", \"\
  highlight_args\": {}, \"linenos\": false} -->\n\n````python\n\n   {\n       \"groundedness_pro_label\"\
  : True,\n       \"reason\": \"'All Contents are grounded\"\n   }\n   ````\n\n**Usage\
  \ with conversation input**\n\n<!-- literal_block {\"ids\": [], \"classes\": [],\
  \ \"names\": [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {}, \"linenos\"\
  : false} -->\n\n````python\n\n   azure_ai_project = {\n       \"subscription_id\"\
  : \"<subscription_id>\",\n       \"resource_group_name\": \"<resource_group_name>\"\
  ,\n       \"project_name\": \"<project_name>\",\n   }\n   credential = DefaultAzureCredential()\n\
  \n   eval_fn = GroundednessProEvaluator(azure_ai_project, credential)\n   conversation\
  \ = {\n       \"messages\": [\n           {\"role\": \"user\", \"content\": \"What\
  \ is the capital of France?\"},\n           {\"role\": \"assistant\", \"content\"\
  : \"Paris.\", \"context\": \"Paris.\"}\n           {\"role\": \"user\", \"content\"\
  : \"What is the capital of Germany?\"},\n           {\"role\": \"assistant\", \"\
  content\": \"Berlin.\", \"context\": \"Berlin.\"}\n       ]\n   }\n   result = eval_fn(conversation=conversation)\n\
  \   ````\n\n**Output format**\n\n<!-- literal_block {\"ids\": [], \"classes\": [],\
  \ \"names\": [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {}, \"linenos\"\
  : false} -->\n\n````python\n\n   {\n       \"groundedness_pro_label\": 1.0,\n  \
  \     \"evaluation_per_turn\": {\n           \"groundedness_pro_label\": [True,\
  \ True],\n           \"groundedness_pro_reason\": [\"All contents are grounded\"\
  , \"All contents are grounded\"]\n       }\n   }\n   ````"
constructor:
  syntax: GroundednessProEvaluator(credential, azure_ai_project, **kwargs)
  parameters:
  - name: credential
    description: The credential for connecting to Azure AI project. Required
    isRequired: true
    types:
    - <xref:azure.core.credentials.TokenCredential>
  - name: azure_ai_project
    description: 'The scope of the Azure AI project.

      It contains subscription id, resource group, and project name.'
    isRequired: true
    types:
    - <xref:azure.ai.evaluation.AzureAIProject>
  - name: kwargs
    description: Additional arguments to pass to the evaluator.
    isRequired: true
    types:
    - <xref:typing.Any>
