### YamlMime:PythonClass
uid: azure.ai.inference.models.CompletionsUsage
name: CompletionsUsage
fullName: azure.ai.inference.models.CompletionsUsage
module: azure.ai.inference.models
summary: 'Representation of the token counts processed for a completions request.

  Counts consider all tokens across prompts, choices, choice alternates, best_of generations,
  and

  other consumers.'
constructor:
  syntax: 'CompletionsUsage(*args: Any, **kwargs: Any)'
variables:
- description: 'The number of tokens generated across all completions emissions.

    Required.'
  name: completion_tokens
  types:
  - <xref:int>
- description: 'The number of tokens in the provided prompts for the completions request.

    Required.'
  name: prompt_tokens
  types:
  - <xref:int>
- description: 'The total number of tokens processed for the completions request and

    response. Required.'
  name: total_tokens
  types:
  - <xref:int>
methods:
- uid: azure.ai.inference.models.CompletionsUsage.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.inference.models.CompletionsUsage.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.inference.models.CompletionsUsage.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.inference.models.CompletionsUsage.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.inference.models.CompletionsUsage.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.inference.models.CompletionsUsage.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.inference.models.CompletionsUsage.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.CompletionsUsage.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.inference.models.CompletionsUsage.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.CompletionsUsage.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.inference.models.CompletionsUsage.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.inference.models.CompletionsUsage.completion_tokens
  name: completion_tokens
  summary: The number of tokens generated across all completions emissions. Required.
  signature: 'completion_tokens: int'
- uid: azure.ai.inference.models.CompletionsUsage.prompt_tokens
  name: prompt_tokens
  summary: The number of tokens in the provided prompts for the completions request.
    Required.
  signature: 'prompt_tokens: int'
- uid: azure.ai.inference.models.CompletionsUsage.total_tokens
  name: total_tokens
  summary: The total number of tokens processed for the completions request and response.
    Required.
  signature: 'total_tokens: int'
