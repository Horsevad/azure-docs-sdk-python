### YamlMime:PythonClass
uid: azure.ai.projects.models.TruncationObject
name: TruncationObject
fullName: azure.ai.projects.models.TruncationObject
module: azure.ai.projects.models
summary: 'Controls for how a thread will be truncated prior to the run. Use this to
  control the initial

  context window of the run.'
constructor:
  syntax: 'TruncationObject(*args: Any, **kwargs: Any)'
variables:
- description: 'The truncation strategy to use for the thread. The default is `auto`.
    If set to

    `last_messages`, the thread will

    be truncated to the `lastMessages` count most recent messages in the thread. When
    set to

    `auto`, messages in the middle of the thread

    will be dropped to fit the context length of the model, `max_prompt_tokens`. Required.
    Known

    values are: "auto" and "last_messages".'
  name: type
  types:
  - <xref:str>
  - <xref:azure.ai.projects.models.TruncationStrategy>
- description: 'The number of most recent messages from the thread when constructing
    the

    context for the run.'
  name: last_messages
  types:
  - <xref:int>
methods:
- uid: azure.ai.projects.models.TruncationObject.as_dict
  name: as_dict
  summary: Return a dict that can be turned into json using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.projects.models.TruncationObject.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.projects.models.TruncationObject.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.projects.models.TruncationObject.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.projects.models.TruncationObject.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.projects.models.TruncationObject.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.projects.models.TruncationObject.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.projects.models.TruncationObject.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.projects.models.TruncationObject.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.projects.models.TruncationObject.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.projects.models.TruncationObject.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.projects.models.TruncationObject.last_messages
  name: last_messages
  summary: The number of most recent messages from the thread when constructing the
    context for the run.
  signature: 'last_messages: int | None'
- uid: azure.ai.projects.models.TruncationObject.type
  name: type
  summary: 'The truncation strategy to use for the thread. The default is `auto`.
    If set to

    `last_messages`, the thread will

    be truncated to the `lastMessages` count most recent messages in the thread. When
    set to

    `auto`, messages in the middle of the thread

    will be dropped to fit the context length of the model, `max_prompt_tokens`. Required.
    Known

    values are: "auto" and "last_messages".'
  signature: 'type: str | _models.TruncationStrategy'
