### YamlMime:PythonPackage
uid: azure.ai.ml
name: ml
fullName: azure.ai.ml
type: import
functions:
- uid: azure.ai.ml.command
  name: command
  summary: "Creates a Command object which can be used inside a dsl.pipeline function\
    \ or used as a standalone Command job.\n\n]\n:keyword outputs: A mapping of output\
    \ names to output data sources used in the job.\n:type outputs: dict[str, Union[str,\
    \ ~azure.ai.ml.Output]]\n:keyword instance_count: The number of instances or nodes\
    \ to be used by the compute target. Defaults to 1.\n:type instance_count: int\n\
    :keyword instance_type: The type of VM to be used by the compute target.\n:type\
    \ instance_type: str\n:keyword locations: The list of locations where the job\
    \ will run.\n:type locations: list[str]\n:keyword docker_args: Extra arguments\
    \ to pass to the Docker run command. This would override any\n\n   parameters\
    \ that have already been set by the system, or in this section. This parameter\
    \ is only\n   supported for Azure ML compute types."
  signature: 'command(*, name: str | None = None, description: str | None = None,
    tags: Dict | None = None, properties: Dict | None = None, display_name: str |
    None = None, command: str | None = None, experiment_name: str | None = None, environment:
    str | Environment | None = None, environment_variables: Dict | None = None, distribution:
    Dict | MpiDistribution | TensorFlowDistribution | PyTorchDistribution | RayDistribution
    | None = None, compute: str | None = None, inputs: Dict | None = None, outputs:
    Dict | None = None, instance_count: int | None = None, instance_type: str | None
    = None, locations: List[str] | None = None, docker_args: str | None = None, shm_size:
    str | None = None, timeout: int | None = None, code: PathLike | str | None = None,
    identity: ManagedIdentityConfiguration | AmlTokenConfiguration | UserIdentityConfiguration
    | None = None, is_deterministic: bool = True, services: Dict[str, JobService |
    JupyterLabJobService | SshJobService | TensorBoardJobService | VsCodeJobService]
    | None = None, job_tier: str | None = None, priority: str | None = None, **kwargs)
    -> Command'
  parameters:
  - name: shm_size
    description: 'The size of the Docker container''s shared memory block. This should
      be in the

      format of (number)(unit) where the number has to be greater than 0 and the unit
      can be one of

      b(bytes), k(kilobytes), m(megabytes), or g(gigabytes).'
  - name: timeout
    description: The number, in seconds, after which the job will be cancelled.
  - name: code
    description: 'The source code to run the job. Can be a local path or "http:",
      "https:", or "azureml:" url

      pointing to a remote location.'
  - name: identity
    description: The identity that the command job will use while running on compute.
  - name: is_deterministic
    description: 'Specifies whether the Command will return the same output given
      the same input.

      Defaults to True.

      When True, if a Command Component is deterministic and has been run before in
      the current workspace

      with the same input and settings, it will reuse results from a previously submitted
      job when used as a

      node or step in a pipeline. In that scenario, no compute resources will be used.'
  - name: services
    description: 'The interactive services for the node. This is an experimental parameter,
      and may change at

      any time. Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)
      for more information.'
  - name: job_tier
    description: The job tier. Accepted values are "Spot", "Basic", "Standard", or
      "Premium".
  - name: priority
    description: The priority of the job on the compute. Defaults to "Medium".
  return:
    description: A Command object.
    types:
    - <xref:azure.ai.ml.entities.Command>
- uid: azure.ai.ml.load_batch_deployment
  name: load_batch_deployment
  summary: Construct a batch deployment object from yaml file.
  signature: 'load_batch_deployment(source: str | PathLike | IO, *, relative_origin:
    str | None = None, **kwargs) -> BatchDeployment'
  parameters:
  - name: source
    description: 'The local yaml source of a batch deployment object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed batch deployment object.
    types:
    - <xref:azure.ai.ml.entities.BatchDeployment>
- uid: azure.ai.ml.load_batch_endpoint
  name: load_batch_endpoint
  summary: Construct a batch endpoint object from yaml file.
  signature: 'load_batch_endpoint(source: str | PathLike | IO, relative_origin: str
    | None = None, **kwargs) -> BatchEndpoint'
  parameters:
  - name: source
    description: 'The local yaml source of a batch endpoint object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    defaultValue: None
    types:
    - <xref:str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed batch endpoint object.
    types:
    - <xref:azure.ai.ml.entities.BatchEndpoint>
- uid: azure.ai.ml.load_component
  name: load_component
  summary: Load component from local or remote to a component function.
  signature: 'load_component(source: str | PathLike | IO | None = None, *, relative_origin:
    str | None = None, **kwargs) -> CommandComponent | ParallelComponent | PipelineComponent'
  parameters:
  - name: source
    description: 'The local yaml source of a component. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    defaultValue: None
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  - name: client
    description: An MLClient instance.
  - name: name
    description: Name of the component.
  - name: version
    description: Version of the component.
  - name: kwargs
    description: A dictionary of additional configuration parameters.
  return:
    description: A function that can be called with parameters to get a *azure.ai.ml.entities.Component*
    types:
    - <xref:Union>[<xref:azure.ai.ml.entities.CommandComponent>, <xref:azure.ai.ml.entities.ParallelComponent>,
      <xref:azure.ai.ml.entities.PipelineComponent>]
- uid: azure.ai.ml.load_compute
  name: load_compute
  summary: Construct a compute object from a yaml file.
  signature: 'load_compute(source: str | PathLike | IO, *, relative_origin: str |
    None = None, **kwargs) -> Compute'
  parameters:
  - name: source
    description: 'The local yaml source of a compute. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Loaded compute object.
    types:
    - <xref:azure.ai.ml.entities.Compute>
- uid: azure.ai.ml.load_data
  name: load_data
  summary: Construct a data object from yaml file.
  signature: 'load_data(source: str | PathLike | IO, *, relative_origin: str | None
    = None, **kwargs) -> Data'
  parameters:
  - name: source
    description: 'The local yaml source of a data object. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed Data or DataImport object.
    types:
    - <xref:azure.ai.ml.entities.Data>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Data cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_datastore
  name: load_datastore
  summary: Construct a datastore object from a yaml file.
  signature: 'load_datastore(source: str | PathLike | IO, *, relative_origin: str
    | None = None, **kwargs) -> Datastore'
  parameters:
  - name: source
    description: 'The local yaml source of a datastore. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Loaded datastore object.
    types:
    - <xref:azure.ai.ml.entities.Datastore>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Datastore cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_environment
  name: load_environment
  summary: Construct a environment object from yaml file.
  signature: 'load_environment(source: str | PathLike | IO, *, relative_origin: str
    | None = None, **kwargs) -> Environment'
  parameters:
  - name: source
    description: 'The local yaml source of an environment. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed environment object.
    types:
    - <xref:azure.ai.ml.entities.Environment>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Environment cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_job
  name: load_job
  summary: Construct a job object from a yaml file.
  signature: 'load_job(source: str | PathLike | IO, *, relative_origin: str | None
    = None, **kwargs) -> Job'
  parameters:
  - name: source
    description: 'The local yaml source of a job. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Loaded job object.
    types:
    - <xref:azure.ai.ml.entities.Job>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Job cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_model
  name: load_model
  summary: Construct a model object from yaml file.
  signature: 'load_model(source: str | PathLike | IO, *, relative_origin: str | None
    = None, **kwargs) -> Model'
  parameters:
  - name: source
    description: 'The local yaml source of a model. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed model object.
    types:
    - <xref:azure.ai.ml.entities.Model>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Model cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_model_package
  name: load_model_package
  summary: '> [!NOTE]

    > This is an experimental method, and may change at any time. Please see [https://aka.ms/azuremlexperimental](https://aka.ms/azuremlexperimental)
    for more information.

    >


    Construct a model package object from yaml file.'
  signature: 'load_model_package(source: str | PathLike | IO, *, relative_origin:
    str | None = None, **kwargs) -> ModelPackage'
- uid: azure.ai.ml.load_online_deployment
  name: load_online_deployment
  summary: Construct a online deployment object from yaml file.
  signature: 'load_online_deployment(source: str | PathLike | IO, *, relative_origin:
    str | None = None, **kwargs) -> OnlineDeployment'
  parameters:
  - name: source
    description: 'The local yaml source of an online deployment object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed online deployment object.
    types:
    - <xref:azure.ai.ml.entities.OnlineDeployment>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Online Deployment cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_online_endpoint
  name: load_online_endpoint
  summary: Construct a online endpoint object from yaml file.
  signature: 'load_online_endpoint(source: str | PathLike | IO, *, relative_origin:
    str | None = None, **kwargs) -> OnlineEndpoint'
  parameters:
  - name: source
    description: 'The local yaml source of an online endpoint object. Must be either
      a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed online endpoint object.
    types:
    - <xref:azure.ai.ml.entities.OnlineEndpoint>
  exceptions:
  - type: azure.ai.ml.exceptions.ValidationException
    description: 'Raised if Online Endpoint cannot be successfully validated.

      Details will be provided in the error message.'
- uid: azure.ai.ml.load_registry
  name: load_registry
  summary: Load a registry object from a yaml file.
  signature: 'load_registry(source: str | PathLike | IO, *, relative_origin: str |
    None = None, **kwargs) -> Registry'
  parameters:
  - name: source
    description: 'The local yaml source of a registry. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Loaded registry object.
    types:
    - <xref:azure.ai.ml.entities.Registry>
- uid: azure.ai.ml.load_workspace
  name: load_workspace
  summary: Load a workspace object from a yaml file.
  signature: 'load_workspace(source: str | PathLike | IO, *, relative_origin: str
    | None = None, **kwargs) -> Workspace'
  parameters:
  - name: source
    description: 'The local yaml source of a workspace. Must be either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Loaded workspace object.
    types:
    - <xref:azure.ai.ml.entities.Workspace>
- uid: azure.ai.ml.load_workspace_connection
  name: load_workspace_connection
  summary: Construct a workspace connection object from yaml file.
  signature: 'load_workspace_connection(source: str | PathLike | IO, *, relative_origin:
    str | None = None, **kwargs) -> WorkspaceConnection'
  parameters:
  - name: source
    description: 'The local yaml source of a workspace connection object. Must be
      either a

      path to a local file, or an already-open file.

      If the source is a path, it will be open and read.

      An exception is raised if the file does not exist.

      If the source is an open file, the file will be read directly,

      and an exception is raised if the file is not readable.'
    isRequired: true
    types:
    - <xref:Union>[<xref:PathLike>, <xref:str>, <xref:io.TextIOWrapper>]
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
  return:
    description: Constructed workspace connection object.
    types:
    - <xref:azure.ai.ml.entities.WorkspaceConnection>
- uid: azure.ai.ml.load_workspace_hub
  name: load_workspace_hub
  summary: "Load a WorkspaceHub object from a yaml file.\n:param source: The local\
    \ yaml source of a WorkspaceHub. Must be either a\n\n   path to a local file,\
    \ or an already-open file.\n   If the source is a path, it will be open and read.\n\
    \   An exception is raised if the file does not exist.\n   If the source is an\
    \ open file, the file will be read directly,\n   and an exception is raised if\
    \ the file is not readable."
  signature: 'load_workspace_hub(source: str | PathLike | IO, *, relative_origin:
    str | None = None, **kwargs) -> WorkspaceHub'
  parameters:
  - name: relative_origin
    description: 'The origin to be used when deducing

      the relative locations of files referenced in the parsed yaml.

      Defaults to the inputted source''s directory if it is a file or file path input.

      Defaults to "./" if the source is a stream input with no name value.'
    isRequired: true
    types:
    - <xref:str>
  - name: params_override
    description: 'Fields to overwrite on top of the yaml file.

      Format is [{"field1": "value1"}, {"field2": "value2"}]'
    isRequired: true
    types:
    - <xref:List>[<xref:Dict>]
  - name: source
  return:
    description: Loaded WorkspaceHub object.
    types:
    - <xref:azure.ai.ml.entities.WorkspaceHub>
- uid: azure.ai.ml.spark
  name: spark
  summary: Creates a Spark object which can be used inside a dsl.pipeline function
    or used as a standalone Spark job.
  signature: 'spark(*, experiment_name: str | None = None, name: str | None = None,
    display_name: str | None = None, description: str | None = None, tags: Dict |
    None = None, code: PathLike | str | None = None, entry: Dict[str, str] | SparkJobEntry
    | None = None, py_files: List[str] | None = None, jars: List[str] | None = None,
    files: List[str] | None = None, archives: List[str] | None = None, identity: Dict[str,
    str] | ManagedIdentity | AmlToken | UserIdentity | None = None, driver_cores:
    int | None = None, driver_memory: str | None = None, executor_cores: int | None
    = None, executor_memory: str | None = None, executor_instances: int | None = None,
    dynamic_allocation_enabled: bool | None = None, dynamic_allocation_min_executors:
    int | None = None, dynamic_allocation_max_executors: int | None = None, conf:
    Dict[str, str] | None = None, environment: str | Environment | None = None, inputs:
    Dict | None = None, outputs: Dict | None = None, args: str | None = None, compute:
    str | None = None, resources: Dict | SparkResourceConfiguration | None = None,
    **kwargs) -> Spark'
  parameters:
  - name: experiment_name
    description: The name of the experiment the job will be created under.
  - name: name
    description: The name of the job.
  - name: display_name
    description: The job display name.
  - name: description
    description: The description of the job.
  - name: tags
    description: The dictionary of tags for the job. Tags can be added, removed, and
      updated.
  - name: code
    description: 'The source code to run the job. Can be a local path or "http:",
      "https:", or "azureml:" url pointing

      to a remote location.'
  - name: entry
    description: The file or class entry point.
  - name: py_files
    description: The list of .zip, .egg or .py files to place on the PYTHONPATH for
      Python apps.
  - name: jars
    description: The list of .JAR files to include on the driver and executor classpaths.
  - name: files
    description: The list of files to be placed in the working directory of each executor.
  - name: archives
    description: The list of archives to be extracted into the working directory of
      each executor.
  - name: identity
    description: The identity that the Spark job will use while running on compute.
  - name: driver_cores
    description: The number of cores to use for the driver process, only in cluster
      mode.
  - name: driver_memory
    description: 'The amount of memory to use for the driver process, formatted as
      strings with a size unit

      suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").'
  - name: executor_cores
    description: The number of cores to use on each executor.
  - name: executor_memory
    description: 'The amount of memory to use per executor process, formatted as strings
      with a size unit

      suffix ("k", "m", "g" or "t") (e.g. "512m", "2g").'
  - name: executor_instances
    description: The initial number of executors.
  - name: dynamic_allocation_enabled
    description: 'Whether to use dynamic resource allocation, which scales the number
      of executors

      registered with this application up and down based on the workload.'
  - name: dynamic_allocation_min_executors
    description: 'The lower bound for the number of executors if dynamic allocation
      is

      enabled.'
  - name: dynamic_allocation_max_executors
    description: 'The upper bound for the number of executors if dynamic allocation
      is

      enabled.'
  - name: conf
    description: A dictionary with pre-defined Spark configurations key and values.
  - name: environment
    description: The Azure ML environment to run the job in.
  - name: inputs
    description: A mapping of input names to input data used in the job.
  - name: outputs
    description: A mapping of output names to output data used in the job.
  - name: args
    description: The arguments for the job.
  - name: compute
    description: The compute resource the job runs on.
  - name: resources
    description: The compute resource configuration for the job.
classes:
- azure.ai.ml.AmlTokenConfiguration
- azure.ai.ml.Input
- azure.ai.ml.MLClient
- azure.ai.ml.ManagedIdentityConfiguration
- azure.ai.ml.MpiDistribution
- azure.ai.ml.Output
- azure.ai.ml.PyTorchDistribution
- azure.ai.ml.RayDistribution
- azure.ai.ml.TensorFlowDistribution
- azure.ai.ml.UserIdentityConfiguration
packages:
- azure.ai.ml.automl
- azure.ai.ml.constants
- azure.ai.ml.data_transfer
- azure.ai.ml.dsl
- azure.ai.ml.entities
- azure.ai.ml.identity
- azure.ai.ml.operations
- azure.ai.ml.parallel
- azure.ai.ml.sweep
modules:
- azure.ai.ml.exceptions
